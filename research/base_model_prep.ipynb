{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "094aa4af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c:\\\\Users\\\\rohan\\\\OneDrive\\\\Desktop\\\\New folder\\\\RetailDemandForecast'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.chdir(\"../\")\n",
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3bd82af3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from prophet import Prophet\n",
    "from sklearn.metrics import mean_absolute_error, mean_absolute_percentage_error\n",
    "from typing import Dict, Any\n",
    "from src.retailDemand.entity.config_entity import RetailForecastingConfig\n",
    "from src.retailDemand.utils.common import createDir\n",
    "from src.retailDemand import logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a9f6134",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RetailDemandForecast:\n",
    "    def __init__(self,config:RetailForecastingConfig):\n",
    "        self.config=config\n",
    "        self.data=None\n",
    "        self.model={}\n",
    "        self.forecasts={}\n",
    "        self.results={}\n",
    "        self.logger=logger\n",
    "\n",
    "        createDir([self.config.root_dir,self.config.model_dir,self.config.results_dir])\n",
    "\n",
    "    def dataPrep(self)->pd.DataFrame:\n",
    "        try:\n",
    "            fPath=self.config.dataset_dir/\"features.csv\"\n",
    "            tPath=self.config.dataset_dir/\"train.csv\"\n",
    "            sPath=self.config.dataset_dir/\"stores.csv\"\n",
    "\n",
    "            self.logger.info(\"Loading csv files for merging\")\n",
    "            df1=pd.read_csv(tPath)\n",
    "            df2=pd.read_csv(fPath)\n",
    "            df3=pd.read_csv(sPath)\n",
    "\n",
    "            temp_data=df1.merge(df2,on=['Store','Date','IsHoliday'],how='inner')\n",
    "            final_data=temp_data.merge(df3,on=['Store'],how='inner')\n",
    "\n",
    "            final_data['Date']=pd.to_datetime(final_data['Date'])\n",
    "\n",
    "            final_data['Year']=final_data['Date'].dt.year\n",
    "            final_data['Month']=final_data['Date'].dt.month\n",
    "            final_data['Week']=final_data['Date'].dt.isocalendar().week\n",
    "            final_data['Day_Name']=final_data['Date'].dt.day_name\n",
    "            final_data['Month_Name']=final_data['Date'].dt.month_name\n",
    "\n",
    "            if 'Weekly_Sales' in final_data.columns and 'Weekly_Sales_x' not in final_data.columns:\n",
    "                final_data['Weekly_Sales_x'] = final_data['Weekly_Sales']\n",
    "\n",
    "            self.data = final_data\n",
    "            self.logger.info(f\"Final merged data shape: {final_data.shape}\")\n",
    "            self.logger.info(f\"Columns: {list(final_data.columns)}\")\n",
    "\n",
    "            return final_data\n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"Error loading and merging data: {str(e)}\")\n",
    "            raise\n",
    "\n",
    "    def storeDataPerp(self,store_id:int)->  pd.DataFrame:\n",
    "        if self.data is None:\n",
    "            raise ValueError(\"Data not loaded. Call dataPrep() first.\")\n",
    "        \n",
    "        store_data = self.data[self.data[self.config.store_column] == store_id]\n",
    "\n",
    "        store_data=store_data[[self.config.date_column,self.config.target_column]]\n",
    "        store_data = store_data.groupby(self.config.date_column).sum()\n",
    "        store_data.reset_index(inplace=True)\n",
    "\n",
    "        store_data.columns = ['ds', 'y']\n",
    "\n",
    "        self.logger.info(f\"Prepared data for store {store_id}.\")\n",
    "        return store_data\n",
    "    \n",
    "    def baseModel(self)->Prophet:\n",
    "        model=Prophet(\n",
    "            daily_seasonality=self.config.daily_seasonality,\n",
    "            weekly_seasonality=self.config.weekly_seasonality,\n",
    "            yearly_seasonality=self.config.yearly_seasonality,\n",
    "            seasonality_mode=self.config.seasonality_mode\n",
    "            )\n",
    "        return model\n",
    "\n",
    "    def trainStore(self,store_id:int)-> Prophet:\n",
    "        try:\n",
    "            self.logger.info(f\"Training for store: {store_id}\")\n",
    "            store_data=self.storeDataPerp(store_id=store_id)\n",
    "            train=store_data.iloc[:self.config.train_split]\n",
    "            model=self.baseModel()  \n",
    "            model.fit(train)\n",
    "\n",
    "            self.model[store_id]=model\n",
    "            self.logger.info(f\"model trained for store {store_id}\")\n",
    "            return model\n",
    "        except Exception as e:\n",
    "            self.logger.info(f\"error training model for store {store_id}\")\n",
    "            raise\n",
    "\n",
    "    def predictStore(self,store_id:int)-> pd.DataFrame:\n",
    "        if store_id not in self.model:\n",
    "            raise ValueError(f\"Model for store {store_id} not found. Train the model first.\")\n",
    "        \n",
    "        model=self.model[store_id]\n",
    "\n",
    "        future=model.make_future_dataframe(\n",
    "            periods=self.config.forecast_periods,\n",
    "            freq=self.config.frequency\n",
    "        )\n",
    "        forecast=model.predict(future)\n",
    "        self.forecasts[store_id]=forecast\n",
    "\n",
    "        self.logger.info(f\"Forecasts generated for store {store_id}\")\n",
    "        return forecast\n",
    "    \n",
    "    def modelEval(self,store_id:int)->Dict[str,float]:\n",
    "        store_data=self.storeDataPerp(store_id)\n",
    "        testData=store_data.iloc[self.config.train_split:]\n",
    "        \n",
    "        if store_id not in self.forecasts:\n",
    "            self.forecasts[store_id]=self.predictStore(store_id=store_id)\n",
    "        \n",
    "        forecast=self.forecasts[store_id]\n",
    "        y_pred=forecast['yhat'].tail(len(testData)).values\n",
    "        y_true=testData['y'].values\n",
    "\n",
    "        mape=mean_absolute_percentage_error(y_true=y_true,y_pred=y_pred)*100\n",
    "        mae=mean_absolute_error(y_true,y_pred)\n",
    "\n",
    "        metrics = {\n",
    "            'MAPE': round(mape, 4),\n",
    "            'MAE': round(mae, 4)\n",
    "        }\n",
    "\n",
    "        self.results[store_id] = metrics\n",
    "        self.logger.info(f\"Evaluation completed for store {store_id}: MAPE={mape:.2f}%\")\n",
    "\n",
    "        return metrics\n",
    "    \n",
    "    def trainAll(self)-> pd.DataFrame:\n",
    "        if self.data is None:\n",
    "            self.dataPrep()\n",
    "\n",
    "        stores=self.data[self.config.store_column].unique()\n",
    "\n",
    "        self.logger.info(f\"Starting training {len(stores)} stores\")\n",
    "\n",
    "        for store_id in stores:\n",
    "            try:\n",
    "                self.trainStore(store_id)\n",
    "                self.modelEval(store_id)\n",
    "                self.logger.info(f\"Completed {store_id}\")\n",
    "            except Exception as e:\n",
    "                self.logger.error(f\"Failed for store {store_id}\")\n",
    "                continue\n",
    "\n",
    "        resDf=pd.DataFrame.from_dict(self.results,orient='index')\n",
    "        resDf.reset_index(inplace=True)\n",
    "        resDf.columns=['Store','MAPE','MAE']\n",
    "\n",
    "        self.logger.info(\"Model Training completed for{len(stores)\")\n",
    "        return resDf\n",
    "    \n",
    "    def predSales(self,store_id:int,date:str)->Dict[str,Any]:\n",
    "        if store_id not in self.models:\n",
    "            available_stores = list(self.models.keys())\n",
    "            raise ValueError(f\"Model for store {store_id} not found. Available stores: {available_stores}\")\n",
    "        \n",
    "        model=self.model[store_id]\n",
    "        future=pd.DataFrame({'ds',[pd.to_datetime(date)]})\n",
    "        forecast=model.predict(future)\n",
    "\n",
    "        res={\n",
    "            \"store_id\":store_id,\n",
    "            \"prediction_date\":date,\n",
    "            \"predicted_sales\":round(forecast['yhat'].iloc[0],2),\n",
    "            'lower_bound': round(forecast['yhat_lower'].iloc[0], 2),\n",
    "            'upper_bound': round(forecast['yhat_upper'].iloc[0], 2)\n",
    "        }\n",
    "\n",
    "        self.logger.info(f\"prediction for store {store_id} on {date} is ${res['predicted_sales']:,.2f}\")\n",
    "        return res\n",
    "    \n",
    "    def save_model(self)-> None:\n",
    "        self.logger.info(\"Saving models\")\n",
    "\n",
    "        for store_id,model in self.model.items():\n",
    "            model_path=self.config.model_dir/f\"prophet_store_{store_id}.pkl\"\n",
    "            with open(model_path,'wb') as f:\n",
    "                pickle.dump(model,f)\n",
    "        \n",
    "        all_models_path=self.config.model_dir/f\"all_models.pkl\"\n",
    "        with open(all_models_path,'wb') as f:\n",
    "            pickle.dump(self.model,f)\n",
    "            \n",
    "        self.logger.info(f\"All {len(self.models)} models saved successfully\")\n",
    "\n",
    "    def save_res(self)->None:\n",
    "        res_df=pd.DataFrame.from_dict(self.results,orient='index')\n",
    "        res_df.reset_index(inplace=True)\n",
    "        res_df.columns = ['Store', 'MAPE', 'MAE']\n",
    "\n",
    "        results_path = self.config.results_dir / \"model_evaluation_results.csv\"\n",
    "        res_df.to_csv(results_path, index=False)\n",
    "        \n",
    "        self.logger.info(f\"Results saved to {results_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cf91a1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "\n",
    "\n",
    "@dataclass(frozen=True)\n",
    "class PrepareBaseModelConfig:\n",
    "    root_dir:Path\n",
    "    base_model_path:Path\n",
    "    seasonality_mode: str = 'multiplicative'\n",
    "    daily_seasonality: bool = False\n",
    "    weekly_seasonality: bool = True\n",
    "    yearly_seasonality: bool = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ce3ffad",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BaseModelCreation:\n",
    "    def __init__(self,):\n",
    "        pass\n",
    "\n",
    "    def getBaseModel(self)->Prophet:\n",
    "        model=Prophet(\n",
    "\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88171ac7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9356f54a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c96e1cd8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
